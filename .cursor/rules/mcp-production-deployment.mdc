---
description: 
globs: 
alwaysApply: false
---
# MCP Production Deployment Guide (June 2025)

## Deployment Architecture

This project uses **FastMCP 2.0** with `FastMCP.from_fastapi()` for production-ready MCP server deployment. The architecture supports multiple deployment patterns optimized for different use cases.

## Primary Deployment: Streamable HTTP

### Production Configuration
The [fastapi_wrapper.py](mdc:src/mcp_server/fastapi_wrapper.py) is configured for production deployment:

```python
# Production deployment pattern
mcp.run(
    transport="streamable_http",
    host="0.0.0.0",
    port=8000
)
```

### Container Deployment

#### Dockerfile Pattern
```dockerfile
FROM python:3.11-slim

# Install dependencies
COPY pyproject.toml uv.lock ./
RUN pip install uv && uv sync --frozen

# Copy application code
COPY src/ /app/src/
WORKDIR /app

# MCP server startup
CMD ["python", "-m", "src.mcp_server.fastapi_wrapper"]
```

#### Docker Compose Integration
```yaml
# docker-compose.production.yml
version: '3.8'
services:
  mcp-server:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    depends_on:
      - qdrant
      - redis
    
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
      
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"

volumes:
  qdrant_data:
```

## Kubernetes Deployment

### Deployment Manifest
```yaml
# k8s/mcp-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mcp-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mcp-server
  template:
    metadata:
      labels:
        app: mcp-server
    spec:
      containers:
      - name: mcp-server
        image: adv-rag:latest
        ports:
        - containerPort: 8000
        env:
        - name: QDRANT_URL
          value: "http://qdrant-service:6333"
        - name: LOG_LEVEL
          value: "INFO"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### Service Configuration
```yaml
# k8s/mcp-server-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: mcp-server-service
spec:
  selector:
    app: mcp-server
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

## Cloud Deployment Options

### 1. AWS ECS Fargate
```json
{
  "family": "mcp-server",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "256",
  "memory": "512",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "mcp-server",
      "image": "your-account.dkr.ecr.region.amazonaws.com/mcp-server:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "QDRANT_URL",
          "value": "https://your-qdrant-cluster.aws.cloud.qdrant.io"
        }
      ]
    }
  ]
}
```

### 2. Google Cloud Run
```yaml
# cloudrun.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: mcp-server
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "1"
        autoscaling.knative.dev/maxScale: "10"
    spec:
      containers:
      - image: gcr.io/project/mcp-server:latest
        ports:
        - containerPort: 8000
        env:
        - name: QDRANT_URL
          value: "https://your-cluster.qdrant.cloud"
        resources:
          limits:
            cpu: "1"
            memory: "1Gi"
```

### 3. Azure Container Instances
```bash
# Azure CLI deployment
az container create \
  --resource-group mcp-rg \
  --name mcp-server \
  --image your-registry.azurecr.io/mcp-server:latest \
  --ports 8000 \
  --environment-variables \
    QDRANT_URL=https://your-cluster.qdrant.azure \
  --cpu 1 \
  --memory 1
```

## Monitoring and Observability

### Health Checks
Add health check endpoints to [fastapi_wrapper.py](mdc:src/mcp_server/fastapi_wrapper.py):

```python
from fastapi import FastAPI
from fastmcp import FastMCP

# Health check integration
@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.utcnow()}

@app.get("/ready")
async def readiness_check():
    # Check dependencies (Qdrant, etc.)
    try:
        # Verify vector store connection
        await vectorstore.asimilarity_search("health", k=1)
        return {"status": "ready"}
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Not ready: {e}")
```

### Logging Configuration
```python
import logging
from pythonjsonlogger import jsonlogger

# Production logging setup
def setup_production_logging():
    logHandler = logging.StreamHandler()
    formatter = jsonlogger.JsonFormatter(
        "%(asctime)s %(name)s %(levelname)s %(message)s"
    )
    logHandler.setFormatter(formatter)
    logger = logging.getLogger()
    logger.addHandler(logHandler)
    logger.setLevel(logging.INFO)
```

### Metrics Collection
```python
from prometheus_client import Counter, Histogram, start_http_server

# MCP-specific metrics
tool_invocations = Counter(
    'mcp_tool_invocations_total',
    'Total MCP tool invocations',
    ['tool_name', 'status']
)

tool_latency = Histogram(
    'mcp_tool_duration_seconds',
    'MCP tool execution time',
    ['tool_name']
)

# Start metrics server
start_http_server(9090)
```

## Security Configuration

### Authentication
```python
from fastmcp.auth import bearer_auth
import os

# Production authentication
@bearer_auth(os.getenv("MCP_API_KEY"))
async def secured_mcp_server():
    # Secured MCP endpoints
    pass
```

### HTTPS Configuration
```python
# TLS configuration for production
mcp.run(
    transport="streamable_http",
    host="0.0.0.0",
    port=8000,
    ssl_certfile="/path/to/cert.pem",
    ssl_keyfile="/path/to/key.pem"
)
```

### Network Security
```bash
# Firewall rules (example for Ubuntu)
sudo ufw allow 8000/tcp  # MCP server
sudo ufw allow 22/tcp    # SSH
sudo ufw enable
```

## Performance Optimization

### Resource Allocation
```python
# Configure for production load
mcp = FastMCP.from_fastapi(
    app=app,
    max_concurrent_tools=10,  # Limit concurrent tool execution
    timeout=30,               # Tool execution timeout
    memory_limit="1GB"        # Memory constraints
)
```

### Caching Strategy
```python
from functools import lru_cache
import redis

# Redis cache for expensive operations
redis_client = redis.Redis(host='redis', port=6379, db=0)

@lru_cache(maxsize=100)
async def cached_retrieval(query: str):
    # Cache retrieval results
    cache_key = f"retrieval:{hash(query)}"
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    
    result = await perform_retrieval(query)
    redis_client.setex(cache_key, 3600, json.dumps(result))
    return result
```

## Deployment Verification

### Post-Deployment Testing
```bash
# 1. Health check
curl http://your-deployment/health

# 2. MCP tool listing
curl -X POST http://your-deployment/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "id": 1, "method": "tools/list"}'

# 3. Tool execution test
curl -X POST http://your-deployment/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/call",
    "params": {
      "name": "semantic_retriever",
      "arguments": {"text": "test query"}
    }
  }'
```

### Load Testing
```bash
# Use existing verification as load test base
for i in {1..100}; do
  python tests/integration/verify_mcp.py &
done
wait
```

## Deployment Checklist

### Pre-Deployment
- [ ] Environment variables configured
- [ ] Health checks implemented
- [ ] Logging configured
- [ ] Security settings applied
- [ ] Resource limits set

### Deployment
- [ ] Container built and pushed
- [ ] Service deployed
- [ ] Load balancer configured
- [ ] DNS records updated
- [ ] SSL certificates installed

### Post-Deployment
- [ ] Health checks passing
- [ ] All 6 tools discoverable
- [ ] Tool execution working
- [ ] Logs flowing correctly
- [ ] Metrics collection active
- [ ] Backup procedures tested

### Rollback Plan
```bash
# Quick rollback procedure
kubectl rollout undo deployment/mcp-server --to-revision=1

# Or for Docker Compose
docker-compose -f docker-compose.production.yml down
docker-compose -f docker-compose.production.yml up -d --scale mcp-server=3
```

This deployment guide ensures production-ready MCP server hosting with proper monitoring, security, and scalability considerations.
